#Set 2

val x = sc.textFile("/sampledata/abc1.txt")
val y = x.flatMap(n => n.split(" "))
val numAs = y.filter(line => line.contains("a")).count() 
val numBs = y.filter(line => line.contains("b")).count() 
numAs
numBs

------------
Application

DAG /Job 0/ Stage 0
val x = sc.textFile("/sampledata/abc1.txt")
val y = x.flatMap(n => n.split(" "))
val z = y.map(n => (n,1))
z.first()

DAG Job 1/Stage 1
val x = sc.textFile("/sampledata/abc1.txt")
val y = x.flatMap(n => n.split(" "))
val z = y.map(n => (n,1))
z.collect()

DAG  Job 2/Stage 2
val x = sc.textFile("/sampledata/abc1.txt")
val y = x.flatMap(n => n.split(" "))
val z = y.map(n => (n,1))
z.saveAsTextFile("mydata/rddo2")

DAG Job 3/Stage 3 ( involves shuffling)
val x = sc.textFile("/sampledata/abc1.txt")
val y = x.flatMap(n => n.split(" "))
val z = y.map(n => (n,1))
z.repartition(1).saveAsTextFile("mydata/rddo3")

DAG Job 4/Stage 4 ( involves shuffling)
val x = sc.textFile("/sampledata/abc1.txt")
val y = x.flatMap(n => n.split(" "))
val z = y.map(n => (n,1))
val wordcount = z.reduceByKey(_+_)
wordcount.saveAsTextFile("mydata/rddo4")

DAG Job 5/Stage 5 ( involves shuffling)
wordcount.repartition(1).saveAsTextFile("mydata/rddo5")

--Pair RDD: data > (K,V) Ex: This is my content---> This, This is my content

--When working with directory
val mydata = sc.wholeTextFiles("/sampledata")

--caching
val x = sc.textFile("/sampledata/abc1.txt",4).flatMap(n => n.split(" ")).map(word => (word,1)).cache()
x.collect()

--persisting
val y = sc.textFile("/sampledata/abc1.txt",4).flatMap(n => n.split(" ")).map(word => (word,1)).persist()
y.collect()

Resource mgr > application > applicationMaster

--Persisting Options
StorageLevel.
StorageLevel.MEMORY_ONLY_SER ---SAME AS memory_only , stores RDD as serialized objects in JVM memory
StorageLevel.MEMORY_ONLY_2 ---replicated cached partitions of RDD
StorageLevel.MEMORY_ONLY_SER_2 
StorageLevel.MEMORY_AND_DISK
StorageLevel.MEMORY_ONLY
StorageLevel.MEMORY_AND_DISK_2
StorageLevel.MEMORY_AND_DISK_ONLY
StorageLevel.DISK_ONLY
StorageLevel.DISK_ONLY_2

>>> from pyspark import StorageLevel
>>> val x = sc.textFile("/sampledata/abc1.txt",4)
>>> val y = x.flatMap(n => n.split(" "))
>>> val z = y.map(word => (word,1))
>>> z.persist(StorageLevel.DISK_ONLY)
>>> z.unpersist()
>>> z.persist(StorageLevel.MEMORY_ONLY)
>>> z.persist(StorageLevel.MEMORY_AND_DISK_ONLY)
>>> z.collect()

===================================
